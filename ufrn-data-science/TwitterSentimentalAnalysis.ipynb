{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Trabalho 3.ipynb","provenance":[],"collapsed_sections":[]},"interpreter":{"hash":"1e87f45ea6456f954092e3c66abf7b40f0e1d2f9e9713a423f4cac954e0c2624"},"kernelspec":{"display_name":"Python 3.8.10 64-bit (conda)","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"cells":[{"cell_type":"markdown","metadata":{"id":"XW_DhjdJXWuv"},"source":["---\n","\n","Universidade Federal do Rio Grande do Norte\n","\n","Centro de Tecnologia\n","\n","Departamento de Engenharia de Computação e Automação\n","\n","DCA0131 - Ciência de Dados\n","\n","Discente: \n","\n","- Levy Gabriel da Silva Galvão\n","\n","Título: **Natural language processing to sentimental analysis in Tweets with Scikit Learning**\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"L8OZSjc4WW9F"},"source":["## Library import"]},{"cell_type":"code","metadata":{"id":"XJM_4FNfT5Ar","executionInfo":{"status":"ok","timestamp":1631674167440,"user_tz":180,"elapsed":285,"user":{"displayName":"Levy Gabriel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1oZgUqGB_6oi--gsnCQuu9LzMpfCX4SJd3TPucw=s64","userId":"05194170306051508520"}}},"source":["# Libraries\n","\n","# Data manipulation\n","import numpy as np\n","import pandas as pd\n","import sklearn as sl\n","import zipfile as zf\n","import matplotlib.pyplot as plt\n","\n","# Scipy\n","import scipy.stats as stats\n","\n","# Model persistence\n","from joblib import dump, load\n","\n","# Machine Learning\n","from sklearn.utils import shuffle   \n","from sklearn.utils.fixes import loguniform\n","from sklearn.pipeline import Pipeline   \n","from sklearn.feature_extraction.text import CountVectorizer, \\\n","                                            TfidfTransformer\n","from sklearn.metrics import classification_report, \\\n","                            confusion_matrix, \\\n","                            plot_confusion_matrix\n","from sklearn.model_selection import GridSearchCV, \\\n","                                    RandomizedSearchCV, \\\n","                                    train_test_split \n","from sklearn.naive_bayes import GaussianNB, \\\n","                                MultinomialNB, \\\n","                                ComplementNB, \\\n","                                BernoulliNB, \\\n","                                CategoricalNB\n","from sklearn.neural_network import MLPClassifier"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TkyfQiEH7_YZ"},"source":["## Load dataset"]},{"cell_type":"markdown","metadata":{"id":"y2JZVjitZI_N"},"source":["The dataset of choose was taken from the **Kaggle** and it is named Sentimental Analysis for Tweets (https://www.kaggle.com/gargmanas/sentimental-analysis-for-tweets) containing several tweets labeled according to if the person that tweeted has depression. \n","\n","The objective of this notebook is to train a machine learning model capable of identifying depression flags in peoples texts, serving as a premature and quick diagnostics for a mental health situation.\n","\n","Since there is a use of a binary label to indetify depression, it is important to clarify that a label '1' indicates a person with depression and '0' the contrary."]},{"cell_type":"code","metadata":{"id":"SbqCMvSP8Dxq"},"source":["!gdown --id 1vKN2THR4CpqLDD6M_C1sCUqbdwFF6dZg &> /dev/null\n","zip_ref = zf.ZipFile('dataset.zip', 'r')\n","zip_ref.extractall('files')\n","zip_ref.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"iZGz-D0R8lJi","executionInfo":{"elapsed":36,"status":"ok","timestamp":1631671218415,"user":{"displayName":"Levy Gabriel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1oZgUqGB_6oi--gsnCQuu9LzMpfCX4SJd3TPucw=s64","userId":"05194170306051508520"},"user_tz":180},"outputId":"9eaa52d6-c3e8-4952-fe62-d5f3099b6ecc"},"source":["twitter = '/content/files/sentiment_tweets3.csv' # original source: https://www.kaggle.com/gargmanas/sentimental-analysis-for-tweets\n","df = pd.read_csv(twitter, \n","                 usecols=['message to examine', 'label (depression result)'], \n","                 encoding='ISO-8859-1')\n","df.columns = ['text', 'target']\n","df = shuffle(df)\n","df.head()"],"execution_count":null,"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>873</th>\n","      <td>hello everybody !</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>8714</th>\n","      <td>It eats me up knowing I literally Lost a piece...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3204</th>\n","      <td>@amber_benson awesome..what did you tell her? ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2340</th>\n","      <td>@therealTiffany check it out epi. haha it make...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6803</th>\n","      <td>At the bubble house again</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                   text  target\n","873                  hello everybody !                        0\n","8714  It eats me up knowing I literally Lost a piece...       1\n","3204  @amber_benson awesome..what did you tell her? ...       0\n","2340  @therealTiffany check it out epi. haha it make...       0\n","6803                         At the bubble house again        0"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"3R0Da4uzaVJ7"},"source":["Based in the quality of the dataset, there is no further pre processing regarding data cleaning or data imputation, since the info below does not show any null data and less likely the necessity to impute data, since the data is mainly categorical."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oShLHmBU8oxs","executionInfo":{"elapsed":32,"status":"ok","timestamp":1631671218416,"user":{"displayName":"Levy Gabriel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1oZgUqGB_6oi--gsnCQuu9LzMpfCX4SJd3TPucw=s64","userId":"05194170306051508520"},"user_tz":180},"outputId":"650b03ea-0200-4cad-fc0b-036b1db6b1fb"},"source":["df.info()"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","Int64Index: 10314 entries, 873 to 2093\n","Data columns (total 2 columns):\n"," #   Column  Non-Null Count  Dtype \n","---  ------  --------------  ----- \n"," 0   text    10314 non-null  object\n"," 1   target  10314 non-null  int64 \n","dtypes: int64(1), object(1)\n","memory usage: 241.7+ KB\n"]}]},{"cell_type":"markdown","metadata":{"id":"ACjdfT_M9CRz"},"source":["## Holdout"]},{"cell_type":"markdown","metadata":{"id":"E0PdQzvQavA5"},"source":["The data separation strategy used was a simple **holdout**, separating the trian and test set with a classical proportion of 80%/20%."]},{"cell_type":"code","metadata":{"id":"cNl4xDjo9H45"},"source":["train, test = train_test_split(df, test_size=0.2, random_state=42, shuffle=True) # shuffle and holdout\n","\n","y_train = np.array(train['target'])\n","y_test = np.array(test['target'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SUxNJubW-0nZ"},"source":["## Feature extraction"]},{"cell_type":"markdown","metadata":{"id":"nikflyifa8MV"},"source":["Before applying any Machine Learning (ML) algorithm, it is important to notice that textual data from the tweets can not be handled directly in its character format.\n","\n","Regarding this fact it was used the ```CountVectorizer()``` and the ```TfidfTransformer()``` classes from scikit learn to perform a feature extraction. First ```CountVectorizer()``` would transform the collection of text into a matrix of token counts that allows to be inputed in a ML model. For further improvement ```TfidfTransformer()``` was used to remove tokens that occurs frequently, but is less informative.\n","\n","The end product is are train and test matrixes of features that resembles like any other typical numerical data and can be fed normally to any supervised ML model.\n","\n"]},{"cell_type":"code","metadata":{"id":"dGdObPFc-3LQ"},"source":["steps = [('vect', CountVectorizer()), ('tfidf', TfidfTransformer())] # or only TfidfVectorizer\n","pipeline = Pipeline(steps)\n","\n","X_train = pipeline.fit_transform(train['text'])\n","X_test = pipeline.transform(test['text'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jkDHMaQZ_zgo","executionInfo":{"elapsed":24,"status":"ok","timestamp":1631671218420,"user":{"displayName":"Levy Gabriel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1oZgUqGB_6oi--gsnCQuu9LzMpfCX4SJd3TPucw=s64","userId":"05194170306051508520"},"user_tz":180},"outputId":"4b401cee-f83d-4f50-dcdd-2bc25693ebb6"},"source":["print('X_train shape:' + str(X_train.shape))\n","print('X_test shape:' + str(X_test.shape))"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["X_train shape:(8251, 19283)\n","X_test shape:(2063, 19283)\n"]}]},{"cell_type":"markdown","metadata":{"id":"6zJwo0HX9xdA"},"source":["## Neural Network"]},{"cell_type":"markdown","metadata":{"id":"on0X5DSUdUMd"},"source":["The first ML model used was a Neural Network, allowing to demonstrate the use of a robust and adaptive algorithm and that used the help of a hyperparameter tunning based in a randomized search.\n","\n","The list of parameters distribution used have multiply solvers and activation functions avaliable in the ```MLPClassifier()``` (multi-layer perceptron classifier) class. Also a log-unfirom function was fed regarding the learning rate e alpha hyperparameters for the neural network."]},{"cell_type":"code","metadata":{"id":"D1AfjCFnJVy0"},"source":["def run(clf, X_train, X_test, y_train, y_test):\n","  param_dist = {'solver': ['lbfgs','sgd','adam'],\n","                'activation': ['identity', 'logistic', 'tanh', 'relu'],\n","                'learning_rate_init' : loguniform(1e-4, 1e0),\n","                'alpha': loguniform(1e-4, 1e0)}\n","  model = RandomizedSearchCV(clf, param_distributions=param_dist, n_iter=10)\n","  model = model.fit(X_train, y_train)\n","  predictions = model.predict(X_test)\n","  print('best params')\n","  print(model.best_params_)\n","  print('best score')\n","  print(model.best_score_)\n","  print('best estimator')\n","  print(model.best_estimator_)\n","  print(classification_report(y_test, predictions))\n","  print(confusion_matrix(y_test, predictions))\n","  plot_confusion_matrix(model, X_test, y_test, cmap='gray', values_format='d')  \n","  plt.show()  \n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VsiU3AdDecOD"},"source":["The classifier was instantiated with a arbitrary number of hidden layer and hidden layer sizes, allowing shuffle at each iteration, a tolerance in the order of $10^{-3}$ and 100 maximum iterations."]},{"cell_type":"code","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"QHgTUnBpJDlG","outputId":"e2a16500-ecd9-4b9f-ef45-48ca902218fa"},"source":["clf = MLPClassifier(random_state=0, max_iter=100, verbose=True, shuffle=True, tol=1e-3, hidden_layer_sizes=(100,100,100))\n","model = run(clf, X_train, X_test, y_train, y_test)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Iteration 1, loss = 0.53134707\n","Iteration 2, loss = 0.49933494\n","Iteration 3, loss = 0.07413741\n","Iteration 4, loss = 0.01621251\n","Iteration 5, loss = 0.00931130\n","Iteration 6, loss = 0.00803816\n","Iteration 7, loss = 0.00790922\n","Iteration 8, loss = 0.00772659\n","Iteration 9, loss = 0.00770736\n","Iteration 10, loss = 0.00755340\n","Iteration 11, loss = 0.00769692\n","Iteration 12, loss = 0.00757116\n","Iteration 13, loss = 0.00754865\n","Iteration 14, loss = 0.00750606\n","Iteration 15, loss = 0.00745314\n","Iteration 16, loss = 0.00740697\n","Iteration 17, loss = 0.00732131\n","Iteration 18, loss = 0.00729755\n","Iteration 19, loss = 0.00733725\n","Iteration 20, loss = 0.00727314\n","Iteration 21, loss = 0.00709256\n","Iteration 22, loss = 0.00718188\n","Iteration 23, loss = 0.00706109\n","Iteration 24, loss = 0.00691169\n","Iteration 25, loss = 0.00690534\n","Iteration 26, loss = 0.00708114\n","Iteration 27, loss = 0.00706182\n","Iteration 28, loss = 0.00707179\n","Iteration 29, loss = 0.00711733\n","Iteration 30, loss = 0.00716799\n","Iteration 31, loss = 0.00706267\n","Iteration 32, loss = 0.00699627\n","Iteration 33, loss = 0.00685924\n","Iteration 34, loss = 0.00679785\n","Iteration 35, loss = 0.00682817\n","Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n","Iteration 1, loss = 0.53260955\n","Iteration 2, loss = 0.63046173\n","Iteration 3, loss = 0.29285343\n","Iteration 4, loss = 0.03068030\n","Iteration 5, loss = 0.00942001\n","Iteration 6, loss = 0.00661471\n","Iteration 7, loss = 0.00654207\n","Iteration 8, loss = 0.00623511\n","Iteration 9, loss = 0.00622943\n","Iteration 10, loss = 0.00606846\n","Iteration 11, loss = 0.00602308\n","Iteration 12, loss = 0.00594125\n","Iteration 13, loss = 0.00584828\n","Iteration 14, loss = 0.00590178\n","Iteration 15, loss = 0.00580950\n","Iteration 16, loss = 0.00569535\n","Iteration 17, loss = 0.00561725\n","Iteration 18, loss = 0.00560032\n","Iteration 19, loss = 0.00561372\n","Iteration 20, loss = 0.00550537\n","Iteration 21, loss = 0.00545751\n","Iteration 22, loss = 0.00540552\n","Iteration 23, loss = 0.00539537\n","Iteration 24, loss = 0.00532135\n","Iteration 25, loss = 0.00521369\n","Iteration 26, loss = 0.00530707\n","Iteration 27, loss = 0.00538597\n","Iteration 28, loss = 0.00513146\n","Iteration 29, loss = 0.00511521\n","Iteration 30, loss = 0.00506432\n","Iteration 31, loss = 0.00516740\n","Iteration 32, loss = 0.00501109\n","Iteration 33, loss = 0.00498880\n","Iteration 34, loss = 0.00494908\n","Iteration 35, loss = 0.00490599\n","Iteration 36, loss = 0.00488841\n","Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n","Iteration 1, loss = 0.53769396\n","Iteration 2, loss = 0.64282790\n","Iteration 3, loss = 0.56571081\n","Iteration 4, loss = 0.57236312\n","Iteration 5, loss = 0.63022146\n","Iteration 6, loss = 0.56419232\n","Iteration 7, loss = 0.55690312\n","Iteration 8, loss = 1.70114362\n","Iteration 9, loss = 1.63017339\n","Iteration 10, loss = 1.98407107\n","Iteration 11, loss = 1.72742751\n","Iteration 12, loss = 1.41606326\n","Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n","Iteration 1, loss = 0.54131325\n","Iteration 2, loss = 0.60544457\n","Iteration 3, loss = 0.40203042\n","Iteration 4, loss = 1.00259688\n","Iteration 5, loss = 0.61285342\n","Iteration 6, loss = 0.66042606\n","Iteration 7, loss = 0.65235345\n","Iteration 8, loss = 2.04230935\n","Iteration 9, loss = 1.78029623\n","Iteration 10, loss = 2.22268699\n","Iteration 11, loss = 1.64423287\n","Iteration 12, loss = 1.82913605\n","Iteration 13, loss = 1.84501495\n","Iteration 14, loss = 1.58233456\n","Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n","Iteration 1, loss = 0.53929210\n","Iteration 2, loss = 0.63483687\n","Iteration 3, loss = 0.55073694\n","Iteration 4, loss = 0.46042840\n","Iteration 5, loss = 0.76042512\n","Iteration 6, loss = 0.68911239\n","Iteration 7, loss = 0.56731231\n","Iteration 8, loss = 1.53244001\n","Iteration 9, loss = 0.88391008\n","Iteration 10, loss = 0.97835720\n","Iteration 11, loss = 1.01356224\n","Iteration 12, loss = 1.20727314\n","Iteration 13, loss = 0.79989345\n","Iteration 14, loss = 0.71047489\n","Iteration 15, loss = 0.98609675\n","Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n","Iteration 1, loss = 0.56065439\n","Iteration 2, loss = 0.53289983\n","Iteration 3, loss = 0.53170992\n","Iteration 4, loss = 0.53346377\n","Iteration 5, loss = 0.52664254\n","Iteration 6, loss = 0.39408420\n","Iteration 7, loss = 0.14147646\n","Iteration 8, loss = 0.08895254\n","Iteration 9, loss = 0.07009101\n","Iteration 10, loss = 0.05643365\n","Iteration 11, loss = 0.04578172\n","Iteration 12, loss = 0.04215492\n","Iteration 13, loss = 0.04314905\n","Iteration 14, loss = 0.04043928\n","Iteration 15, loss = 0.04309897\n","Iteration 16, loss = 0.05231573\n","Iteration 17, loss = 0.05924954\n","Iteration 18, loss = 0.05127492\n","Iteration 19, loss = 0.05770549\n","Iteration 20, loss = 0.05291493\n","Iteration 21, loss = 0.05671938\n","Iteration 22, loss = 0.06053964\n","Iteration 23, loss = 0.06307624\n","Iteration 24, loss = 0.05940636\n","Iteration 25, loss = 0.05149258\n","Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n","Iteration 1, loss = 0.56601661\n","Iteration 2, loss = 0.54109417\n","Iteration 3, loss = 0.57338702\n","Iteration 4, loss = 0.61582119\n","Iteration 5, loss = 0.64182410\n","Iteration 6, loss = 0.62941449\n","Iteration 7, loss = 0.59189366\n","Iteration 8, loss = 0.56538265\n","Iteration 9, loss = 0.55290693\n","Iteration 10, loss = 0.54619223\n","Iteration 11, loss = 0.54482165\n","Iteration 12, loss = 0.54123060\n","Iteration 13, loss = 0.55297628\n","Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n","Iteration 1, loss = 0.57516731\n","Iteration 2, loss = 0.54189172\n","Iteration 3, loss = 0.57155380\n","Iteration 4, loss = 0.61574607\n","Iteration 5, loss = 0.64290556\n","Iteration 6, loss = 0.63120832\n","Iteration 7, loss = 0.59127860\n","Iteration 8, loss = 0.58251369\n","Iteration 9, loss = 0.55345740\n","Iteration 10, loss = 0.54788323\n","Iteration 11, loss = 0.54306855\n","Iteration 12, loss = 0.54359854\n","Iteration 13, loss = 0.54208669\n","Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n","Iteration 1, loss = 0.57798426\n","Iteration 2, loss = 0.54197441\n","Iteration 3, loss = 0.57294001\n","Iteration 4, loss = 0.61676754\n","Iteration 5, loss = 0.64231112\n","Iteration 6, loss = 0.62699303\n","Iteration 7, loss = 0.59033302\n","Iteration 8, loss = 0.58819903\n","Iteration 9, loss = 0.55294550\n","Iteration 10, loss = 0.55053469\n","Iteration 11, loss = 0.54298160\n","Iteration 12, loss = 0.54354436\n","Iteration 13, loss = 0.54086594\n","Iteration 14, loss = 0.54262715\n","Iteration 15, loss = 0.54264611\n","Iteration 16, loss = 0.54781308\n","Iteration 17, loss = 0.54889477\n","Iteration 18, loss = 0.55722402\n","Iteration 19, loss = 0.56410471\n","Iteration 20, loss = 0.57125771\n","Iteration 21, loss = 0.57658382\n","Iteration 22, loss = 0.58007589\n","Iteration 23, loss = 0.57903192\n","Iteration 24, loss = 0.57564601\n","Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n","Iteration 1, loss = 0.57299023\n","Iteration 2, loss = 0.54190494\n","Iteration 3, loss = 0.57475027\n","Iteration 4, loss = 0.61568947\n","Iteration 5, loss = 0.64263642\n","Iteration 6, loss = 0.62764443\n","Iteration 7, loss = 0.58805449\n","Iteration 8, loss = 0.58967998\n","Iteration 9, loss = 0.55187462\n","Iteration 10, loss = 0.55116660\n","Iteration 11, loss = 0.54264953\n","Iteration 12, loss = 0.54244658\n","Iteration 13, loss = 0.54081887\n","Iteration 14, loss = 0.54347673\n","Iteration 15, loss = 0.54204972\n","Iteration 16, loss = 0.54790600\n","Iteration 17, loss = 0.54848637\n","Iteration 18, loss = 0.55580255\n","Iteration 19, loss = 0.56470896\n","Iteration 20, loss = 0.57024541\n","Iteration 21, loss = 0.58611329\n","Iteration 22, loss = 0.58031227\n","Iteration 23, loss = 0.58018264\n","Iteration 24, loss = 0.57476889\n","Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n","Iteration 1, loss = 13.75093614\n","Iteration 2, loss = 3.69969549\n","Iteration 3, loss = 1.87439272\n","Iteration 4, loss = 1.03962846\n","Iteration 5, loss = 0.82117996\n","Iteration 6, loss = 0.71248425\n","Iteration 7, loss = 0.64297398\n","Iteration 8, loss = 0.60549634\n","Iteration 9, loss = 0.60672456\n","Iteration 10, loss = 0.62304673\n","Iteration 11, loss = 0.67214788\n","Iteration 12, loss = 0.58038845\n","Iteration 13, loss = 0.63226236\n","Iteration 14, loss = 0.67048927\n","Iteration 15, loss = 0.55601728\n","Iteration 16, loss = 0.54568080\n","Iteration 17, loss = 0.67062476\n","Iteration 18, loss = 0.56009598\n","Iteration 19, loss = 0.55977221\n","Iteration 20, loss = 0.54391383\n","Iteration 21, loss = 0.57686873\n","Iteration 22, loss = 0.54659210\n","Iteration 23, loss = 0.55836098\n","Iteration 24, loss = 0.56488463\n","Iteration 25, loss = 0.55479589\n","Iteration 26, loss = 0.56256173\n","Iteration 27, loss = 0.54803001\n","Iteration 28, loss = 0.63642796\n","Iteration 29, loss = 0.59825305\n","Iteration 30, loss = 0.58645174\n","Iteration 31, loss = 0.60987308\n","Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n","Iteration 1, loss = 13.69759782\n","Iteration 2, loss = 160.31573948\n","Iteration 3, loss = 592.72510512\n","Iteration 4, loss = 1413.28176037\n","Iteration 5, loss = 2518.25728660\n","Iteration 6, loss = 2101.99355407\n","Iteration 7, loss = 1301.05292021\n","Iteration 8, loss = 716.49168705\n","Iteration 9, loss = 417.19338398\n","Iteration 10, loss = 286.97666830\n","Iteration 11, loss = 219.74452262\n","Iteration 12, loss = 183.09128206\n","Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n","Iteration 1, loss = 13.58838154\n","Iteration 2, loss = 160.56996626\n","Iteration 3, loss = 592.95151647\n","Iteration 4, loss = 1413.73304896\n","Iteration 5, loss = 2517.01325953\n","Iteration 6, loss = 2101.86044041\n","Iteration 7, loss = 1301.32086608\n","Iteration 8, loss = 717.62307507\n","Iteration 9, loss = 417.88257654\n","Iteration 10, loss = 288.04487334\n","Iteration 11, loss = 219.66340872\n","Iteration 12, loss = 182.86369827\n","Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n","Iteration 1, loss = 13.83846520\n","Iteration 2, loss = 161.53919600\n","Iteration 3, loss = 594.57961324\n","Iteration 4, loss = 1411.86696448\n","Iteration 5, loss = 2510.74166092\n","Iteration 6, loss = 2099.95710243\n","Iteration 7, loss = 1303.07196708\n","Iteration 8, loss = 718.41615762\n","Iteration 9, loss = 417.38090012\n","Iteration 10, loss = 287.70499962\n","Iteration 11, loss = 220.50090587\n","Iteration 12, loss = 184.15049262\n","Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n","Iteration 1, loss = 13.81769198\n","Iteration 2, loss = 161.02495155\n","Iteration 3, loss = 593.33563415\n","Iteration 4, loss = 1413.81235671\n","Iteration 5, loss = 2519.28659764\n","Iteration 6, loss = 2102.14442682\n","Iteration 7, loss = 1300.33769615\n","Iteration 8, loss = 716.42752127\n","Iteration 9, loss = 417.47492387\n","Iteration 10, loss = 288.06682072\n","Iteration 11, loss = 220.41215900\n","Iteration 12, loss = 183.36356161\n","Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n","Iteration 1, loss = 0.55307601\n","Iteration 2, loss = 0.52566627\n","Iteration 3, loss = 0.52188907\n","Iteration 4, loss = 0.51706683\n","Iteration 5, loss = 0.50925668\n","Iteration 6, loss = 0.49652955\n","Iteration 7, loss = 0.47298183\n","Iteration 8, loss = 0.42773318\n","Iteration 9, loss = 0.34025971\n","Iteration 10, loss = 0.21935989\n","Iteration 11, loss = 0.12367360\n","Iteration 12, loss = 0.07481694\n","Iteration 13, loss = 0.05135930\n","Iteration 14, loss = 0.03856561\n","Iteration 15, loss = 0.03025312\n","Iteration 16, loss = 0.02468943\n","Iteration 17, loss = 0.02060854\n","Iteration 18, loss = 0.01765841\n","Iteration 19, loss = 0.01522217\n","Iteration 20, loss = 0.01316722\n","Iteration 21, loss = 0.01163283\n","Iteration 22, loss = 0.01022282\n","Iteration 23, loss = 0.00921622\n","Iteration 24, loss = 0.00832882\n","Iteration 25, loss = 0.00763894\n","Iteration 26, loss = 0.00704394\n","Iteration 27, loss = 0.00665371\n","Iteration 28, loss = 0.00625851\n","Iteration 29, loss = 0.00588691\n","Iteration 30, loss = 0.00568557\n","Iteration 31, loss = 0.00543897\n","Iteration 32, loss = 0.00520238\n","Iteration 33, loss = 0.00503649\n","Iteration 34, loss = 0.00489925\n","Iteration 35, loss = 0.00479822\n","Iteration 36, loss = 0.00461294\n","Iteration 37, loss = 0.00461190\n","Iteration 38, loss = 0.00439063\n","Iteration 39, loss = 0.00436812\n","Iteration 40, loss = 0.00432907\n","Iteration 41, loss = 0.00419933\n","Iteration 42, loss = 0.00409353\n","Iteration 43, loss = 0.00407067\n","Iteration 44, loss = 0.00395723\n","Iteration 45, loss = 0.00393782\n","Iteration 46, loss = 0.00398771\n","Iteration 47, loss = 0.00392012\n","Iteration 48, loss = 0.00387653\n","Iteration 49, loss = 0.00378011\n","Iteration 50, loss = 0.00376725\n","Iteration 51, loss = 0.00370234\n","Iteration 52, loss = 0.00369176\n","Iteration 53, loss = 0.00365961\n","Iteration 54, loss = 0.00361284\n","Iteration 55, loss = 0.00366410\n","Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n","Iteration 1, loss = 0.55187889\n","Iteration 2, loss = 0.52588117\n","Iteration 3, loss = 0.52195512\n","Iteration 4, loss = 0.51722241\n","Iteration 5, loss = 0.50996392\n","Iteration 6, loss = 0.49801164\n","Iteration 7, loss = 0.47527984\n","Iteration 8, loss = 0.43073740\n","Iteration 9, loss = 0.34661798\n","Iteration 10, loss = 0.22452392\n","Iteration 11, loss = 0.12450481\n","Iteration 12, loss = 0.07414451\n","Iteration 13, loss = 0.05014503\n","Iteration 14, loss = 0.03668103\n","Iteration 15, loss = 0.02871909\n","Iteration 16, loss = 0.02319000\n","Iteration 17, loss = 0.01924975\n","Iteration 18, loss = 0.01632580\n","Iteration 19, loss = 0.01379616\n","Iteration 20, loss = 0.01202980\n","Iteration 21, loss = 0.01040961\n","Iteration 22, loss = 0.00904610\n","Iteration 23, loss = 0.00842728\n","Iteration 24, loss = 0.00729269\n","Iteration 25, loss = 0.00643541\n","Iteration 26, loss = 0.00584750\n","Iteration 27, loss = 0.00544523\n","Iteration 28, loss = 0.00502352\n","Iteration 29, loss = 0.00473718\n","Iteration 30, loss = 0.00445641\n","Iteration 31, loss = 0.00422218\n","Iteration 32, loss = 0.00400934\n","Iteration 33, loss = 0.00384839\n","Iteration 34, loss = 0.00369820\n","Iteration 35, loss = 0.00355259\n","Iteration 36, loss = 0.00343961\n","Iteration 37, loss = 0.00331037\n","Iteration 38, loss = 0.00323173\n","Iteration 39, loss = 0.00315295\n","Iteration 40, loss = 0.00303759\n","Iteration 41, loss = 0.00300929\n","Iteration 42, loss = 0.00291330\n","Iteration 43, loss = 0.00285018\n","Iteration 44, loss = 0.00285366\n","Iteration 45, loss = 0.00277887\n","Iteration 46, loss = 0.00273056\n","Iteration 47, loss = 0.00267615\n","Iteration 48, loss = 0.00265196\n","Iteration 49, loss = 0.00261086\n","Iteration 50, loss = 0.00256258\n","Iteration 51, loss = 0.00254580\n","Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n","Iteration 1, loss = 0.55417637\n","Iteration 2, loss = 0.52599744\n","Iteration 3, loss = 0.52213216\n","Iteration 4, loss = 0.51729797\n","Iteration 5, loss = 0.50998278\n","Iteration 6, loss = 0.49805399\n","Iteration 7, loss = 0.47498801\n","Iteration 8, loss = 0.43863532\n","Iteration 9, loss = 0.34850322\n","Iteration 10, loss = 0.24095662\n","Iteration 11, loss = 0.12731392\n","Iteration 12, loss = 0.07612668\n","Iteration 13, loss = 0.05204894\n","Iteration 14, loss = 0.03850348\n","Iteration 15, loss = 0.03026225\n","Iteration 16, loss = 0.02441661\n","Iteration 17, loss = 0.02036396\n","Iteration 18, loss = 0.01722834\n","Iteration 19, loss = 0.01466437\n","Iteration 20, loss = 0.01268083\n","Iteration 21, loss = 0.01107394\n","Iteration 22, loss = 0.00970994\n","Iteration 23, loss = 0.00870704\n","Iteration 24, loss = 0.00760895\n","Iteration 25, loss = 0.00680262\n","Iteration 26, loss = 0.00625776\n","Iteration 27, loss = 0.00567554\n","Iteration 28, loss = 0.00525916\n","Iteration 29, loss = 0.00490674\n","Iteration 30, loss = 0.00461649\n","Iteration 31, loss = 0.00432222\n","Iteration 32, loss = 0.00412762\n","Iteration 33, loss = 0.00394362\n","Iteration 34, loss = 0.00383250\n","Iteration 35, loss = 0.00364733\n","Iteration 36, loss = 0.00354283\n","Iteration 37, loss = 0.00338797\n","Iteration 38, loss = 0.00327303\n","Iteration 39, loss = 0.00319683\n","Iteration 40, loss = 0.00310733\n","Iteration 41, loss = 0.00302581\n","Iteration 42, loss = 0.00297259\n","Iteration 43, loss = 0.00289650\n","Iteration 44, loss = 0.00289746\n","Iteration 45, loss = 0.00280030\n","Iteration 46, loss = 0.00274899\n","Iteration 47, loss = 0.00269479\n","Iteration 48, loss = 0.00263873\n","Iteration 49, loss = 0.00260397\n","Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n","Iteration 1, loss = 0.55441231\n","Iteration 2, loss = 0.52622407\n","Iteration 3, loss = 0.52249386\n","Iteration 4, loss = 0.51714661\n","Iteration 5, loss = 0.50937179\n","Iteration 6, loss = 0.49717117\n","Iteration 7, loss = 0.47255426\n","Iteration 8, loss = 0.43592106\n","Iteration 9, loss = 0.34035094\n","Iteration 10, loss = 0.23137836\n","Iteration 11, loss = 0.12087927\n","Iteration 12, loss = 0.07234119\n","Iteration 13, loss = 0.04921785\n","Iteration 14, loss = 0.03613509\n","Iteration 15, loss = 0.02835683\n","Iteration 16, loss = 0.02286666\n","Iteration 17, loss = 0.01879465\n","Iteration 18, loss = 0.01607991\n","Iteration 19, loss = 0.01376005\n","Iteration 20, loss = 0.01204892\n","Iteration 21, loss = 0.01069073\n","Iteration 22, loss = 0.00960386\n","Iteration 23, loss = 0.00865441\n","Iteration 24, loss = 0.00783890\n","Iteration 25, loss = 0.00718313\n","Iteration 26, loss = 0.00674274\n","Iteration 27, loss = 0.00631303\n","Iteration 28, loss = 0.00597995\n","Iteration 29, loss = 0.00577481\n","Iteration 30, loss = 0.00552985\n","Iteration 31, loss = 0.00529179\n","Iteration 32, loss = 0.00509022\n","Iteration 33, loss = 0.00494056\n","Iteration 34, loss = 0.00484901\n","Iteration 35, loss = 0.00471825\n","Iteration 36, loss = 0.00458298\n","Iteration 37, loss = 0.00449126\n","Iteration 38, loss = 0.00440473\n","Iteration 39, loss = 0.00427403\n","Iteration 40, loss = 0.00429603\n","Iteration 41, loss = 0.00419541\n","Iteration 42, loss = 0.00410836\n","Iteration 43, loss = 0.00413262\n","Iteration 44, loss = 0.00401229\n","Iteration 45, loss = 0.00398617\n","Iteration 46, loss = 0.00396039\n","Iteration 47, loss = 0.00395242\n","Iteration 48, loss = 0.00384739\n","Iteration 49, loss = 0.00379904\n","Iteration 50, loss = 0.00381814\n","Iteration 51, loss = 0.00376346\n","Iteration 52, loss = 0.00373609\n","Iteration 53, loss = 0.00367838\n","Iteration 54, loss = 0.00369257\n","Iteration 55, loss = 0.00363198\n","Iteration 56, loss = 0.00361229\n","Iteration 57, loss = 0.00443418\n","Iteration 58, loss = 0.00362749\n","Iteration 59, loss = 0.00353675\n","Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n","Iteration 1, loss = 0.55501984\n","Iteration 2, loss = 0.52616472\n","Iteration 3, loss = 0.52303122\n","Iteration 4, loss = 0.51746726\n","Iteration 5, loss = 0.50937485\n","Iteration 6, loss = 0.49691176\n","Iteration 7, loss = 0.47170732\n","Iteration 8, loss = 0.43320325\n","Iteration 9, loss = 0.33700225\n","Iteration 10, loss = 0.22821314\n","Iteration 11, loss = 0.11971106\n","Iteration 12, loss = 0.07318073\n","Iteration 13, loss = 0.05038586\n","Iteration 14, loss = 0.03783485\n","Iteration 15, loss = 0.03043949\n","Iteration 16, loss = 0.02467373\n","Iteration 17, loss = 0.02050961\n","Iteration 18, loss = 0.01775530\n","Iteration 19, loss = 0.01528413\n","Iteration 20, loss = 0.01349977\n","Iteration 21, loss = 0.14393476\n","Iteration 22, loss = 0.01659419\n","Iteration 23, loss = 0.01385361\n","Iteration 24, loss = 0.01196081\n","Iteration 25, loss = 0.01038112\n","Iteration 26, loss = 0.00929161\n","Iteration 27, loss = 0.00831312\n","Iteration 28, loss = 0.00763873\n","Iteration 29, loss = 0.00709296\n","Iteration 30, loss = 0.00664299\n","Iteration 31, loss = 0.00619845\n","Iteration 32, loss = 0.00589519\n","Iteration 33, loss = 0.00558699\n","Iteration 34, loss = 0.00538596\n","Iteration 35, loss = 0.00523651\n","Iteration 36, loss = 0.00507015\n","Iteration 37, loss = 0.00491195\n","Iteration 38, loss = 0.00475659\n","Iteration 39, loss = 0.00459851\n","Iteration 40, loss = 0.00457809\n","Iteration 41, loss = 0.00445619\n","Iteration 42, loss = 0.00435521\n","Iteration 43, loss = 0.00454663\n","Iteration 44, loss = 0.00422132\n","Iteration 45, loss = 0.00417920\n","Iteration 46, loss = 0.00410371\n","Iteration 47, loss = 0.00410573\n","Iteration 48, loss = 0.00400433\n","Iteration 49, loss = 0.00395403\n","Iteration 50, loss = 0.00394069\n","Iteration 51, loss = 0.00390828\n","Iteration 52, loss = 0.00386228\n","Iteration 53, loss = 0.00380385\n","Iteration 54, loss = 0.00379220\n","Iteration 55, loss = 0.00376083\n","Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n","Iteration 1, loss = 0.66991663\n","Iteration 2, loss = 0.64604045\n","Iteration 3, loss = 0.62519049\n","Iteration 4, loss = 0.60806487\n","Iteration 5, loss = 0.59425467\n","Iteration 6, loss = 0.58316469\n","Iteration 7, loss = 0.57401163\n","Iteration 8, loss = 0.56652495\n","Iteration 9, loss = 0.56048862\n","Iteration 10, loss = 0.55549940\n","Iteration 11, loss = 0.55140403\n","Iteration 12, loss = 0.54805190\n","Iteration 13, loss = 0.54528800\n","Iteration 14, loss = 0.54298741\n","Iteration 15, loss = 0.54112318\n","Iteration 16, loss = 0.53955441\n","Iteration 17, loss = 0.53828670\n","Iteration 18, loss = 0.53718646\n","Iteration 19, loss = 0.53629660\n","Iteration 20, loss = 0.53556345\n","Iteration 21, loss = 0.53493033\n","Iteration 22, loss = 0.53442780\n","Iteration 23, loss = 0.53396079\n","Iteration 24, loss = 0.53360424\n","Iteration 25, loss = 0.53328420\n","Iteration 26, loss = 0.53301392\n","Iteration 27, loss = 0.53277820\n","Iteration 28, loss = 0.53257690\n","Iteration 29, loss = 0.53239880\n","Iteration 30, loss = 0.53224898\n","Iteration 31, loss = 0.53210894\n","Iteration 32, loss = 0.53198226\n","Iteration 33, loss = 0.53187456\n","Iteration 34, loss = 0.53177332\n","Iteration 35, loss = 0.53168253\n","Iteration 36, loss = 0.53159571\n","Iteration 37, loss = 0.53151682\n","Iteration 38, loss = 0.53143487\n","Iteration 39, loss = 0.53136506\n","Iteration 40, loss = 0.53129496\n","Iteration 41, loss = 0.53123238\n","Iteration 42, loss = 0.53116418\n","Iteration 43, loss = 0.53110344\n","Iteration 44, loss = 0.53104474\n","Iteration 45, loss = 0.53098207\n","Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n","Iteration 1, loss = 0.67012209\n","Iteration 2, loss = 0.64507462\n","Iteration 3, loss = 0.62324469\n","Iteration 4, loss = 0.60553137\n","Iteration 5, loss = 0.59153601\n","Iteration 6, loss = 0.58015320\n","Iteration 7, loss = 0.57105352\n","Iteration 8, loss = 0.56364579\n","Iteration 9, loss = 0.55765287\n","Iteration 10, loss = 0.55282792\n","Iteration 11, loss = 0.54891889\n","Iteration 12, loss = 0.54569961\n","Iteration 13, loss = 0.54383104\n","Iteration 14, loss = 0.54179586\n","Iteration 15, loss = 0.53992839\n","Iteration 16, loss = 0.53841334\n","Iteration 17, loss = 0.53722405\n","Iteration 18, loss = 0.53620069\n","Iteration 19, loss = 0.53576979\n","Iteration 20, loss = 0.53513296\n","Iteration 21, loss = 0.53449892\n","Iteration 22, loss = 0.53398022\n","Iteration 23, loss = 0.53383019\n","Iteration 24, loss = 0.53352323\n","Iteration 25, loss = 0.53315066\n","Iteration 26, loss = 0.53287181\n","Iteration 27, loss = 0.53264868\n","Iteration 28, loss = 0.53243307\n","Iteration 29, loss = 0.53227118\n","Iteration 30, loss = 0.53213343\n","Iteration 31, loss = 0.53201250\n","Iteration 32, loss = 0.53191805\n","Iteration 33, loss = 0.53181988\n","Iteration 34, loss = 0.53181789\n","Iteration 35, loss = 0.53172226\n","Iteration 36, loss = 0.53164470\n","Iteration 37, loss = 0.53164532\n","Iteration 38, loss = 0.53161703\n","Iteration 39, loss = 0.53153744\n","Iteration 40, loss = 0.53145368\n","Iteration 41, loss = 0.53136648\n","Iteration 42, loss = 0.53133151\n","Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n","Iteration 1, loss = 0.67013124\n","Iteration 2, loss = 0.64503139\n","Iteration 3, loss = 0.62329780\n","Iteration 4, loss = 0.60557370\n","Iteration 5, loss = 0.59150047\n","Iteration 6, loss = 0.58016381\n","Iteration 7, loss = 0.57106314\n","Iteration 8, loss = 0.56481407\n","Iteration 9, loss = 0.55897053\n","Iteration 10, loss = 0.55483273\n","Iteration 11, loss = 0.55080470\n","Iteration 12, loss = 0.54726124\n","Iteration 13, loss = 0.54438498\n","Iteration 14, loss = 0.54205554\n","Iteration 15, loss = 0.54012631\n","Iteration 16, loss = 0.53859049\n","Iteration 17, loss = 0.53736324\n","Iteration 18, loss = 0.53631202\n","Iteration 19, loss = 0.53548965\n","Iteration 20, loss = 0.53479074\n","Iteration 21, loss = 0.53424612\n","Iteration 22, loss = 0.53377143\n","Iteration 23, loss = 0.53339732\n","Iteration 24, loss = 0.53309606\n","Iteration 25, loss = 0.53282538\n","Iteration 26, loss = 0.53261362\n","Iteration 27, loss = 0.53245767\n","Iteration 28, loss = 0.53228345\n","Iteration 29, loss = 0.53215334\n","Iteration 30, loss = 0.53204468\n","Iteration 31, loss = 0.53194693\n","Iteration 32, loss = 0.53187874\n","Iteration 33, loss = 0.53179278\n","Iteration 34, loss = 0.53177945\n","Iteration 35, loss = 0.53170011\n","Iteration 36, loss = 0.53162672\n","Iteration 37, loss = 0.53162055\n","Iteration 38, loss = 0.53158954\n","Iteration 39, loss = 0.53151212\n","Iteration 40, loss = 0.53142867\n","Iteration 41, loss = 0.53135768\n","Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n","Iteration 1, loss = 0.67004753\n","Iteration 2, loss = 0.64500035\n","Iteration 3, loss = 0.62323431\n","Iteration 4, loss = 0.60561197\n","Iteration 5, loss = 0.59148770\n","Iteration 6, loss = 0.58021283\n","Iteration 7, loss = 0.57108034\n","Iteration 8, loss = 0.56486012\n","Iteration 9, loss = 0.55900622\n","Iteration 10, loss = 0.55490288\n","Iteration 11, loss = 0.55087331\n","Iteration 12, loss = 0.54733664\n","Iteration 13, loss = 0.54449177\n","Iteration 14, loss = 0.54212655\n","Iteration 15, loss = 0.54021915\n","Iteration 16, loss = 0.53867335\n","Iteration 17, loss = 0.53745682\n","Iteration 18, loss = 0.53639681\n","Iteration 19, loss = 0.53557875\n","Iteration 20, loss = 0.53488461\n","Iteration 21, loss = 0.53433159\n","Iteration 22, loss = 0.53385873\n","Iteration 23, loss = 0.53349113\n","Iteration 24, loss = 0.53318931\n","Iteration 25, loss = 0.53292161\n","Iteration 26, loss = 0.53270411\n","Iteration 27, loss = 0.53254140\n","Iteration 28, loss = 0.53237483\n","Iteration 29, loss = 0.53224687\n","Iteration 30, loss = 0.53214135\n","Iteration 31, loss = 0.53204018\n","Iteration 32, loss = 0.53197798\n","Iteration 33, loss = 0.53188887\n","Iteration 34, loss = 0.53185776\n","Iteration 35, loss = 0.53178496\n","Iteration 36, loss = 0.53171603\n","Iteration 37, loss = 0.53169753\n","Iteration 38, loss = 0.53161608\n","Iteration 39, loss = 0.53153957\n","Iteration 40, loss = 0.53147944\n","Iteration 41, loss = 0.53142351\n","Iteration 42, loss = 0.53136906\n","Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n","Iteration 1, loss = 0.67012759\n","Iteration 2, loss = 0.64510371\n","Iteration 3, loss = 0.62327945\n","Iteration 4, loss = 0.60569317\n","Iteration 5, loss = 0.59157774\n","Iteration 6, loss = 0.58028931\n","Iteration 7, loss = 0.57114913\n","Iteration 8, loss = 0.56493861\n","Iteration 9, loss = 0.55909847\n","Iteration 10, loss = 0.55497535\n","Iteration 11, loss = 0.55096092\n","Iteration 12, loss = 0.54741307\n","Iteration 13, loss = 0.54458363\n","Iteration 14, loss = 0.54220980\n","Iteration 15, loss = 0.54033441\n","Iteration 16, loss = 0.53875589\n","Iteration 17, loss = 0.53753723\n","Iteration 18, loss = 0.53648645\n","Iteration 19, loss = 0.53567805\n","Iteration 20, loss = 0.53497257\n","Iteration 21, loss = 0.53471719\n","Iteration 22, loss = 0.53427997\n","Iteration 23, loss = 0.53385850\n","Iteration 24, loss = 0.53348837\n","Iteration 25, loss = 0.53318109\n","Iteration 26, loss = 0.53292616\n","Iteration 27, loss = 0.53271498\n","Iteration 28, loss = 0.53253564\n","Iteration 29, loss = 0.53239239\n","Iteration 30, loss = 0.53225856\n","Iteration 31, loss = 0.53215249\n","Iteration 32, loss = 0.53208968\n","Iteration 33, loss = 0.53197829\n","Iteration 34, loss = 0.53193114\n","Iteration 35, loss = 0.53187557\n","Iteration 36, loss = 0.53179766\n","Iteration 37, loss = 0.53180202\n","Iteration 38, loss = 0.53169772\n","Iteration 39, loss = 0.53168595\n","Iteration 40, loss = 0.53160504\n","Iteration 41, loss = 0.53152556\n","Iteration 42, loss = 0.53145589\n","Iteration 43, loss = 0.53140370\n","Iteration 44, loss = 0.53134965\n","Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n","Iteration 1, loss = 0.58894700\n","Iteration 2, loss = 0.52904114\n","Iteration 3, loss = 0.52792820\n","Iteration 4, loss = 0.52696685\n","Iteration 5, loss = 0.52610866\n","Iteration 6, loss = 0.52515530\n","Iteration 7, loss = 0.52415989\n","Iteration 8, loss = 0.52312279\n","Iteration 9, loss = 0.52199714\n","Iteration 10, loss = 0.52080284\n","Iteration 11, loss = 0.51954433\n","Iteration 12, loss = 0.51810419\n","Iteration 13, loss = 0.51659397\n","Iteration 14, loss = 0.51493312\n","Iteration 15, loss = 0.51295569\n","Iteration 16, loss = 0.51089648\n","Iteration 17, loss = 0.50856975\n","Iteration 18, loss = 0.50577684\n","Iteration 19, loss = 0.50271489\n","Iteration 20, loss = 0.49922938\n","Iteration 21, loss = 0.49529097\n","Iteration 22, loss = 0.49068091\n","Iteration 23, loss = 0.48538990\n","Iteration 24, loss = 0.47907410\n","Iteration 25, loss = 0.47179683\n","Iteration 26, loss = 0.46337920\n","Iteration 27, loss = 0.45336998\n","Iteration 28, loss = 0.44153807\n","Iteration 29, loss = 0.42761283\n","Iteration 30, loss = 0.41118512\n","Iteration 31, loss = 0.39223851\n","Iteration 32, loss = 0.37030907\n","Iteration 33, loss = 0.34560490\n","Iteration 34, loss = 0.31848667\n","Iteration 35, loss = 0.28972203\n","Iteration 36, loss = 0.25992663\n","Iteration 37, loss = 0.23100279\n","Iteration 38, loss = 0.20387661\n","Iteration 39, loss = 0.17920056\n","Iteration 40, loss = 0.15735645\n","Iteration 41, loss = 0.13852464\n","Iteration 42, loss = 0.12256594\n","Iteration 43, loss = 0.10903708\n","Iteration 44, loss = 0.09741283\n","Iteration 45, loss = 0.08796532\n","Iteration 46, loss = 0.07953931\n","Iteration 47, loss = 0.07270852\n","Iteration 48, loss = 0.06662495\n","Iteration 49, loss = 0.06118366\n","Iteration 50, loss = 0.05666108\n","Iteration 51, loss = 0.05262931\n","Iteration 52, loss = 0.04920333\n","Iteration 53, loss = 0.04591274\n","Iteration 54, loss = 0.04303655\n","Iteration 55, loss = 0.04056144\n","Iteration 56, loss = 0.03829076\n","Iteration 57, loss = 0.03629555\n","Iteration 58, loss = 0.03430234\n","Iteration 59, loss = 0.03258321\n","Iteration 60, loss = 0.03108395\n","Iteration 61, loss = 0.02957490\n","Iteration 62, loss = 0.02817165\n","Iteration 63, loss = 0.02700652\n","Iteration 64, loss = 0.02585003\n","Iteration 65, loss = 0.02480021\n","Iteration 66, loss = 0.02380376\n","Iteration 67, loss = 0.02284884\n","Iteration 68, loss = 0.02198390\n","Iteration 69, loss = 0.02118974\n","Iteration 70, loss = 0.02037139\n","Iteration 71, loss = 0.01966189\n","Iteration 72, loss = 0.01902002\n","Iteration 73, loss = 0.01830902\n","Iteration 74, loss = 0.01761051\n","Iteration 75, loss = 0.01714550\n","Iteration 76, loss = 0.01656346\n","Iteration 77, loss = 0.01596999\n","Iteration 78, loss = 0.01553275\n","Iteration 79, loss = 0.01500352\n","Iteration 80, loss = 0.01462250\n","Iteration 81, loss = 0.01418321\n","Iteration 82, loss = 0.01371832\n","Iteration 83, loss = 0.01336654\n","Iteration 84, loss = 0.01302321\n","Iteration 85, loss = 0.01263131\n","Iteration 86, loss = 0.01226103\n","Iteration 87, loss = 0.01192997\n","Iteration 88, loss = 0.01161218\n","Iteration 89, loss = 0.01135702\n","Iteration 90, loss = 0.01104218\n","Iteration 91, loss = 0.01074969\n","Iteration 92, loss = 0.01052251\n","Iteration 93, loss = 0.01027318\n","Iteration 94, loss = 0.01005162\n","Iteration 95, loss = 0.00980880\n","Iteration 96, loss = 0.00959616\n","Iteration 97, loss = 0.00938223\n","Iteration 98, loss = 0.00918027\n","Iteration 99, loss = 0.00899364\n","Iteration 100, loss = 0.00886015\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning:\n","\n","Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Iteration 1, loss = 0.58927421\n","Iteration 2, loss = 0.52932306\n","Iteration 3, loss = 0.52819617\n","Iteration 4, loss = 0.52713868\n","Iteration 5, loss = 0.52627763\n","Iteration 6, loss = 0.52546953\n","Iteration 7, loss = 0.52442796\n","Iteration 8, loss = 0.52333965\n","Iteration 9, loss = 0.52242262\n","Iteration 10, loss = 0.52116464\n","Iteration 11, loss = 0.51990232\n","Iteration 12, loss = 0.51846466\n","Iteration 13, loss = 0.51794435\n","Iteration 14, loss = 0.51519152\n","Iteration 15, loss = 0.51344141\n","Iteration 16, loss = 0.51149829\n","Iteration 17, loss = 0.50929186\n","Iteration 18, loss = 0.50651718\n","Iteration 19, loss = 0.50508852\n","Iteration 20, loss = 0.50015267\n","Iteration 21, loss = 0.49616990\n","Iteration 22, loss = 0.49164218\n","Iteration 23, loss = 0.48818814\n","Iteration 24, loss = 0.48101983\n","Iteration 25, loss = 0.47330581\n","Iteration 26, loss = 0.46517935\n","Iteration 27, loss = 0.45541423\n","Iteration 28, loss = 0.44387887\n","Iteration 29, loss = 0.43084093\n","Iteration 30, loss = 0.41498330\n","Iteration 31, loss = 0.39661701\n","Iteration 32, loss = 0.37506451\n","Iteration 33, loss = 0.35039919\n","Iteration 34, loss = 0.32804165\n","Iteration 35, loss = 0.29362516\n","Iteration 36, loss = 0.26378103\n","Iteration 37, loss = 0.23348825\n","Iteration 38, loss = 0.20453631\n","Iteration 39, loss = 0.17776960\n","Iteration 40, loss = 0.15567764\n","Iteration 41, loss = 0.13684809\n","Iteration 42, loss = 0.12066629\n","Iteration 43, loss = 0.10688901\n","Iteration 44, loss = 0.09550083\n","Iteration 45, loss = 0.08583955\n","Iteration 46, loss = 0.07756719\n","Iteration 47, loss = 0.07053879\n","Iteration 48, loss = 0.06450493\n","Iteration 49, loss = 0.05920624\n","Iteration 50, loss = 0.05461732\n","Iteration 51, loss = 0.05081972\n","Iteration 52, loss = 0.04721304\n","Iteration 53, loss = 0.04405640\n","Iteration 54, loss = 0.04124191\n","Iteration 55, loss = 0.03874032\n","Iteration 56, loss = 0.04872084\n","Iteration 57, loss = 0.03720616\n","Iteration 58, loss = 0.03233415\n","Iteration 59, loss = 0.03042571\n","Iteration 60, loss = 0.03374264\n","Iteration 61, loss = 0.02745218\n","Iteration 62, loss = 0.02637298\n","Iteration 63, loss = 0.02489685\n","Iteration 64, loss = 0.02376573\n","Iteration 65, loss = 0.02284380\n","Iteration 66, loss = 0.02186582\n","Iteration 67, loss = 0.02103168\n","Iteration 68, loss = 0.02017266\n","Iteration 69, loss = 0.01942210\n","Iteration 70, loss = 0.01867273\n","Iteration 71, loss = 0.01798000\n","Iteration 72, loss = 0.01902304\n","Iteration 73, loss = 0.01671290\n","Iteration 74, loss = 0.01603795\n","Iteration 75, loss = 0.01550424\n","Iteration 76, loss = 0.01500006\n","Iteration 77, loss = 0.01444979\n","Iteration 78, loss = 0.01401712\n","Iteration 79, loss = 0.01355624\n","Iteration 80, loss = 0.01312927\n","Iteration 81, loss = 0.01267217\n","Iteration 82, loss = 0.01228561\n","Iteration 83, loss = 0.01194911\n","Iteration 84, loss = 0.01152310\n","Iteration 85, loss = 0.01118120\n","Iteration 86, loss = 0.01091369\n","Iteration 87, loss = 0.01061146\n","Iteration 88, loss = 0.01025788\n","Iteration 89, loss = 0.00998049\n","Iteration 90, loss = 0.00966032\n","Iteration 91, loss = 0.04855823\n","Iteration 92, loss = 0.01048955\n","Iteration 93, loss = 0.00993011\n","Iteration 94, loss = 0.00999505\n","Iteration 95, loss = 0.00920990\n","Iteration 96, loss = 0.00890494\n","Iteration 97, loss = 0.00865722\n","Iteration 98, loss = 0.00843501\n","Iteration 99, loss = 0.00817373\n","Iteration 100, loss = 0.00799499\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning:\n","\n","Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Iteration 1, loss = 0.59010009\n","Iteration 2, loss = 0.52902703\n","Iteration 3, loss = 0.52831338\n","Iteration 4, loss = 0.52712125\n","Iteration 5, loss = 0.52619056\n","Iteration 6, loss = 0.52543731\n","Iteration 7, loss = 0.52444932\n","Iteration 8, loss = 0.52449860\n","Iteration 9, loss = 0.52251297\n","Iteration 10, loss = 0.52192459\n","Iteration 11, loss = 0.51960906\n","Iteration 12, loss = 0.51836393\n","Iteration 13, loss = 0.51679658\n","Iteration 14, loss = 0.51511377\n","Iteration 15, loss = 0.51316755\n","Iteration 16, loss = 0.51118942\n","Iteration 17, loss = 0.50887996\n","Iteration 18, loss = 0.50614847\n","Iteration 19, loss = 0.50309756\n","Iteration 20, loss = 0.49949986\n","Iteration 21, loss = 0.49558164\n","Iteration 22, loss = 0.49089357\n","Iteration 23, loss = 0.48564677\n","Iteration 24, loss = 0.47954347\n","Iteration 25, loss = 0.47213399\n","Iteration 26, loss = 0.46381113\n","Iteration 27, loss = 0.45372212\n","Iteration 28, loss = 0.44180218\n","Iteration 29, loss = 0.42795657\n","Iteration 30, loss = 0.41134765\n","Iteration 31, loss = 0.39233389\n","Iteration 32, loss = 0.37047346\n","Iteration 33, loss = 0.34490004\n","Iteration 34, loss = 0.32281237\n","Iteration 35, loss = 0.28716881\n","Iteration 36, loss = 0.25758384\n","Iteration 37, loss = 0.22752136\n","Iteration 38, loss = 0.19959256\n","Iteration 39, loss = 0.17307563\n","Iteration 40, loss = 0.15173083\n","Iteration 41, loss = 0.13357429\n","Iteration 42, loss = 0.11824068\n","Iteration 43, loss = 0.10488316\n","Iteration 44, loss = 0.09417445\n","Iteration 45, loss = 0.08488235\n","Iteration 46, loss = 0.07691528\n","Iteration 47, loss = 0.07004705\n","Iteration 48, loss = 0.06423925\n","Iteration 49, loss = 0.05925423\n","Iteration 50, loss = 0.05485393\n","Iteration 51, loss = 0.05108964\n","Iteration 52, loss = 0.04756426\n","Iteration 53, loss = 0.04446196\n","Iteration 54, loss = 0.04181784\n","Iteration 55, loss = 0.03928631\n","Iteration 56, loss = 0.04874625\n","Iteration 57, loss = 0.04023445\n","Iteration 58, loss = 0.03307105\n","Iteration 59, loss = 0.03112717\n","Iteration 60, loss = 0.02969450\n","Iteration 61, loss = 0.02826131\n","Iteration 62, loss = 0.02708520\n","Iteration 63, loss = 0.02572527\n","Iteration 64, loss = 0.02466418\n","Iteration 65, loss = 0.02365241\n","Iteration 66, loss = 0.02258246\n","Iteration 67, loss = 0.02180950\n","Iteration 68, loss = 0.02082633\n","Iteration 69, loss = 0.02009920\n","Iteration 70, loss = 0.01934819\n","Iteration 71, loss = 0.01859358\n","Iteration 72, loss = 0.01793757\n","Iteration 73, loss = 0.01729686\n","Iteration 74, loss = 0.01667317\n","Iteration 75, loss = 0.01608664\n","Iteration 76, loss = 0.01553818\n","Iteration 77, loss = 0.01500694\n","Iteration 78, loss = 0.01452320\n","Iteration 79, loss = 0.01406583\n","Iteration 80, loss = 0.01367722\n","Iteration 81, loss = 0.01315676\n","Iteration 82, loss = 0.01271787\n","Iteration 83, loss = 0.01240010\n","Iteration 84, loss = 0.01197577\n","Iteration 85, loss = 0.01162485\n","Iteration 86, loss = 0.01137580\n","Iteration 87, loss = 0.01096805\n","Iteration 88, loss = 0.01063586\n","Iteration 89, loss = 0.01032541\n","Iteration 90, loss = 0.01006135\n","Iteration 91, loss = 0.04585186\n","Iteration 92, loss = 0.01089446\n","Iteration 93, loss = 0.01018858\n","Iteration 94, loss = 0.00983916\n","Iteration 95, loss = 0.00954242\n","Iteration 96, loss = 0.00923029\n","Iteration 97, loss = 0.00897141\n","Iteration 98, loss = 0.00870340\n","Iteration 99, loss = 0.00846777\n","Iteration 100, loss = 0.00821702\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning:\n","\n","Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Iteration 1, loss = 0.58981070\n","Iteration 2, loss = 0.52889214\n","Iteration 3, loss = 0.52839734\n","Iteration 4, loss = 0.52724988\n","Iteration 5, loss = 0.52630160\n","Iteration 6, loss = 0.52552911\n","Iteration 7, loss = 0.52439413\n","Iteration 8, loss = 0.52413138\n","Iteration 9, loss = 0.52226075\n","Iteration 10, loss = 0.52195650\n","Iteration 11, loss = 0.51959551\n","Iteration 12, loss = 0.51827597\n","Iteration 13, loss = 0.51677745\n","Iteration 14, loss = 0.51492119\n","Iteration 15, loss = 0.51298363\n","Iteration 16, loss = 0.51096226\n","Iteration 17, loss = 0.50865722\n","Iteration 18, loss = 0.50578510\n","Iteration 19, loss = 0.50281141\n","Iteration 20, loss = 0.49897157\n","Iteration 21, loss = 0.49489383\n","Iteration 22, loss = 0.49012023\n","Iteration 23, loss = 0.48463247\n","Iteration 24, loss = 0.47836879\n","Iteration 25, loss = 0.47076066\n","Iteration 26, loss = 0.46205275\n","Iteration 27, loss = 0.45167699\n","Iteration 28, loss = 0.43933385\n","Iteration 29, loss = 0.42510718\n","Iteration 30, loss = 0.40802202\n","Iteration 31, loss = 0.38807563\n","Iteration 32, loss = 0.36527525\n","Iteration 33, loss = 0.33969145\n","Iteration 34, loss = 0.31353846\n","Iteration 35, loss = 0.27990271\n","Iteration 36, loss = 0.25049335\n","Iteration 37, loss = 0.22012481\n","Iteration 38, loss = 0.19284870\n","Iteration 39, loss = 0.16914969\n","Iteration 40, loss = 0.14791794\n","Iteration 41, loss = 0.13011493\n","Iteration 42, loss = 0.11497188\n","Iteration 43, loss = 0.10178084\n","Iteration 44, loss = 0.09124506\n","Iteration 45, loss = 0.08228739\n","Iteration 46, loss = 0.07426363\n","Iteration 47, loss = 0.06751117\n","Iteration 48, loss = 0.06544289\n","Iteration 49, loss = 0.05610982\n","Iteration 50, loss = 0.05183067\n","Iteration 51, loss = 0.04805298\n","Iteration 52, loss = 0.04496114\n","Iteration 53, loss = 0.04172364\n","Iteration 54, loss = 0.03919796\n","Iteration 55, loss = 0.03675873\n","Iteration 56, loss = 0.03476752\n","Iteration 57, loss = 0.03700456\n","Iteration 58, loss = 0.03110317\n","Iteration 59, loss = 0.02939734\n","Iteration 60, loss = 0.02806450\n","Iteration 61, loss = 0.02662988\n","Iteration 62, loss = 0.02559601\n","Iteration 63, loss = 0.02422701\n","Iteration 64, loss = 0.02314228\n","Iteration 65, loss = 0.02214740\n","Iteration 66, loss = 0.02121924\n","Iteration 67, loss = 0.02046435\n","Iteration 68, loss = 0.01961019\n","Iteration 69, loss = 0.01890421\n","Iteration 70, loss = 0.01815949\n","Iteration 71, loss = 0.01744914\n","Iteration 72, loss = 0.01689423\n","Iteration 73, loss = 0.01629799\n","Iteration 74, loss = 0.01575075\n","Iteration 75, loss = 0.01521072\n","Iteration 76, loss = 0.01483443\n","Iteration 77, loss = 0.01422947\n","Iteration 78, loss = 0.01380301\n","Iteration 79, loss = 0.01339490\n","Iteration 80, loss = 0.01299511\n","Iteration 81, loss = 0.01268774\n","Iteration 82, loss = 0.01231090\n","Iteration 83, loss = 0.01193118\n","Iteration 84, loss = 0.01160345\n","Iteration 85, loss = 0.01132500\n","Iteration 86, loss = 0.01258030\n","Iteration 87, loss = 0.01068165\n","Iteration 88, loss = 0.01040709\n","Iteration 89, loss = 0.01013249\n","Iteration 90, loss = 0.00996044\n","Iteration 91, loss = 0.00980335\n","Iteration 92, loss = 0.00946730\n","Iteration 93, loss = 0.00926062\n","Iteration 94, loss = 0.00909976\n","Iteration 95, loss = 0.00887134\n","Iteration 96, loss = 0.00871233\n","Iteration 97, loss = 0.00852673\n","Iteration 98, loss = 0.00839949\n","Iteration 99, loss = 0.00825644\n","Iteration 100, loss = 0.00810104\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning:\n","\n","Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Iteration 1, loss = 0.59003075\n","Iteration 2, loss = 0.52901985\n","Iteration 3, loss = 0.52851776\n","Iteration 4, loss = 0.52734536\n","Iteration 5, loss = 0.52638661\n","Iteration 6, loss = 0.52551631\n","Iteration 7, loss = 0.52440849\n","Iteration 8, loss = 0.52405172\n","Iteration 9, loss = 0.52224314\n","Iteration 10, loss = 0.52203670\n","Iteration 11, loss = 0.51957793\n","Iteration 12, loss = 0.51819513\n","Iteration 13, loss = 0.51676052\n","Iteration 14, loss = 0.51482674\n","Iteration 15, loss = 0.51296275\n","Iteration 16, loss = 0.51071141\n","Iteration 17, loss = 0.50837601\n","Iteration 18, loss = 0.50556277\n","Iteration 19, loss = 0.50247670\n","Iteration 20, loss = 0.49868124\n","Iteration 21, loss = 0.49626845\n","Iteration 22, loss = 0.48976927\n","Iteration 23, loss = 0.48438230\n","Iteration 24, loss = 0.47784622\n","Iteration 25, loss = 0.47038517\n","Iteration 26, loss = 0.46132566\n","Iteration 27, loss = 0.45074897\n","Iteration 28, loss = 0.43827261\n","Iteration 29, loss = 0.42379398\n","Iteration 30, loss = 0.40632022\n","Iteration 31, loss = 0.38658175\n","Iteration 32, loss = 0.36373913\n","Iteration 33, loss = 0.33735551\n","Iteration 34, loss = 0.31012733\n","Iteration 35, loss = 0.27743397\n","Iteration 36, loss = 0.24828643\n","Iteration 37, loss = 0.21823760\n","Iteration 38, loss = 0.19130929\n","Iteration 39, loss = 0.16769859\n","Iteration 40, loss = 0.14639772\n","Iteration 41, loss = 0.12922661\n","Iteration 42, loss = 0.11427314\n","Iteration 43, loss = 0.10859839\n","Iteration 44, loss = 0.09059327\n","Iteration 45, loss = 0.08202487\n","Iteration 46, loss = 0.07430737\n","Iteration 47, loss = 0.06801879\n","Iteration 48, loss = 0.06531825\n","Iteration 49, loss = 0.05708734\n","Iteration 50, loss = 0.05294645\n","Iteration 51, loss = 0.04936363\n","Iteration 52, loss = 0.04624553\n","Iteration 53, loss = 0.04314439\n","Iteration 54, loss = 0.04061334\n","Iteration 55, loss = 0.03836643\n","Iteration 56, loss = 0.03638814\n","Iteration 57, loss = 0.03736853\n","Iteration 58, loss = 0.03266439\n","Iteration 59, loss = 0.04577598\n","Iteration 60, loss = 0.02927783\n","Iteration 61, loss = 0.02775237\n","Iteration 62, loss = 0.02696912\n","Iteration 63, loss = 0.02533676\n","Iteration 64, loss = 0.02438519\n","Iteration 65, loss = 0.02332071\n","Iteration 66, loss = 0.02252192\n","Iteration 67, loss = 0.02184897\n","Iteration 68, loss = 0.02083562\n","Iteration 69, loss = 0.02004424\n","Iteration 70, loss = 0.01945935\n","Iteration 71, loss = 0.01864773\n","Iteration 72, loss = 0.01803714\n","Iteration 73, loss = 0.01744968\n","Iteration 74, loss = 0.01697395\n","Iteration 75, loss = 0.01637043\n","Iteration 76, loss = 0.01601013\n","Iteration 77, loss = 0.01539680\n","Iteration 78, loss = 0.01498401\n","Iteration 79, loss = 0.01455267\n","Iteration 80, loss = 0.01404192\n","Iteration 81, loss = 0.01366210\n","Iteration 82, loss = 0.01351813\n","Iteration 83, loss = 0.01287731\n","Iteration 84, loss = 0.01252320\n","Iteration 85, loss = 0.01226838\n","Iteration 86, loss = 0.01438865\n","Iteration 87, loss = 0.01156952\n","Iteration 88, loss = 0.01117592\n","Iteration 89, loss = 0.01091064\n","Iteration 90, loss = 0.01069682\n","Iteration 91, loss = 0.01061905\n","Iteration 92, loss = 0.01015149\n","Iteration 93, loss = 0.00992538\n","Iteration 94, loss = 0.00968408\n","Iteration 95, loss = 0.00948237\n","Iteration 96, loss = 0.00931137\n","Iteration 97, loss = 0.00907932\n","Iteration 98, loss = 0.00896673\n","Iteration 99, loss = 0.00873929\n","Iteration 100, loss = 0.00864149\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning:\n","\n","Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning:\n","\n","lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","\n","/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning:\n","\n","lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","\n"]},{"name":"stdout","output_type":"stream","text":["Iteration 1, loss = 0.55016409\n","Iteration 2, loss = 0.52469430\n","Iteration 3, loss = 0.51926070\n","Iteration 4, loss = 0.51131144\n","Iteration 5, loss = 0.49542257\n","Iteration 6, loss = 0.46065540\n","Iteration 7, loss = 0.38130059\n","Iteration 8, loss = 0.23872054\n","Iteration 9, loss = 0.11656871\n","Iteration 10, loss = 0.06455513\n","Iteration 11, loss = 0.04295704\n","Iteration 12, loss = 0.03166332\n","Iteration 13, loss = 0.02471935\n","Iteration 14, loss = 0.02026341\n","Iteration 15, loss = 0.01673811\n","Iteration 16, loss = 0.01408089\n","Iteration 17, loss = 0.01210914\n","Iteration 18, loss = 0.01058046\n","Iteration 19, loss = 0.00910449\n","Iteration 20, loss = 0.00813157\n","Iteration 21, loss = 0.00728533\n","Iteration 22, loss = 0.00664538\n","Iteration 23, loss = 0.00605343\n","Iteration 24, loss = 0.00562745\n","Iteration 25, loss = 0.00523479\n","Iteration 26, loss = 0.00496628\n","Iteration 27, loss = 0.00477392\n","Iteration 28, loss = 0.00445467\n","Iteration 29, loss = 0.00432821\n","Iteration 30, loss = 0.00416368\n","Iteration 31, loss = 0.00404935\n","Iteration 32, loss = 0.00430256\n","Iteration 33, loss = 0.00387452\n","Iteration 34, loss = 0.00372924\n","Iteration 35, loss = 0.00365211\n","Iteration 36, loss = 0.00359797\n","Iteration 37, loss = 0.00356004\n","Iteration 38, loss = 0.00348481\n","Iteration 39, loss = 0.00344950\n","Iteration 40, loss = 0.00337958\n","Iteration 41, loss = 0.00332016\n","Iteration 42, loss = 0.00328670\n","Iteration 43, loss = 0.00322891\n","Iteration 44, loss = 0.00323975\n","Iteration 45, loss = 0.00316967\n","Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n","best params\n","{'activation': 'tanh', 'alpha': 0.00013916767470239526, 'learning_rate_init': 0.010830064209855255, 'solver': 'sgd'}\n","best score\n","0.9946672540058368\n","best estimator\n","MLPClassifier(activation='tanh', alpha=0.00013916767470239526,\n","              batch_size='auto', beta_1=0.9, beta_2=0.999, early_stopping=False,\n","              epsilon=1e-08, hidden_layer_sizes=(100, 100, 100),\n","              learning_rate='constant', learning_rate_init=0.010830064209855255,\n","              max_fun=15000, max_iter=100, momentum=0.9, n_iter_no_change=10,\n","              nesterovs_momentum=True, power_t=0.5, random_state=0,\n","              shuffle=True, solver='sgd', tol=0.0001, validation_fraction=0.1,\n","              verbose=True, warm_start=False)\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      1577\n","           1       1.00      1.00      1.00       486\n","\n","    accuracy                           1.00      2063\n","   macro avg       1.00      1.00      1.00      2063\n","weighted avg       1.00      1.00      1.00      2063\n","\n","[[1576    1]\n"," [   2  484]]\n"]},{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{},"output_type":"display_data"}]},{"cell_type":"markdown","metadata":{"id":"duM0dpfee0P_"},"source":["In the set of estimators trained, the randomized search found the best having a score of $99.46\\%$ turning to be a excelent result.\n","\n","Despite the good results, there are still doubts if the neural network model is the adequate for this dataset, since the the random search of hyperparameters and therefore the training of the model took a substancial time.\n","\n","Albeit the doubts the best estimator was yet saved for latter analysis."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bESeme_9WnDn","executionInfo":{"status":"ok","timestamp":1631674329121,"user_tz":180,"elapsed":432,"user":{"displayName":"Levy Gabriel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1oZgUqGB_6oi--gsnCQuu9LzMpfCX4SJd3TPucw=s64","userId":"05194170306051508520"}},"outputId":"f4ebb370-c2fa-4a4a-8d36-c05dbca76660"},"source":["dump(model, 'mlpclassifier.joblib') \n","#load('mlpclassifier.joblib')"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['mlpclassifier.joblib']"]},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"WpnSyUAzAJZg"},"source":["## Naive Bayes "]},{"cell_type":"markdown","metadata":{"id":"9TvrwrC0fwih"},"source":["The second choice of ML algorithms was a set of Naive Bayes methods. First of all was analysed the use o the \"raw\" models as it is with default parameters provided by the Scikit Learn library. Also a hyperparameter tunning with grid search was performed to see with there is any improvement in the model score."]},{"cell_type":"markdown","metadata":{"id":"LAeQRMGuIkF9"},"source":["### Raw models"]},{"cell_type":"code","metadata":{"id":"t2PC-JR1CI85"},"source":["def run(model, X_train, X_test, y_train, y_test):\n","  model = model.fit(X_train, y_train)\n","  predictions = model.predict(X_test)\n","  print(classification_report(y_test, predictions))\n","  plot_confusion_matrix(model, X_test, y_test, cmap='gray', values_format='d')  \n","  plt.show()  \n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1EQSXMmrgvZi"},"source":["The first model was the ```MultinomialNB``` that implements the naive Bayes algorithm for multinomially distributed data and adequate to text data that are typically represented as word vector counts."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":432},"id":"NgpiXCTZD4U1","executionInfo":{"elapsed":514,"status":"ok","timestamp":1631655662138,"user":{"displayName":"Levy Gabriel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1oZgUqGB_6oi--gsnCQuu9LzMpfCX4SJd3TPucw=s64","userId":"05194170306051508520"},"user_tz":180},"outputId":"5968b1f0-07ce-4128-e5ec-99bb55671a7a"},"source":["model = run(MultinomialNB(), X_train, X_test, y_train, y_test)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.87      1.00      0.93      1587\n","           1       1.00      0.50      0.66       476\n","\n","    accuracy                           0.88      2063\n","   macro avg       0.93      0.75      0.80      2063\n","weighted avg       0.90      0.88      0.87      2063\n","\n"]},{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{},"output_type":"display_data"}]},{"cell_type":"markdown","metadata":{"id":"YQbDgXGahEgo"},"source":["Althought the ```ComplementNB()``` model that implements the complement naive Bayes, typically suited for imbalanced data sets and a improvement in the latter algorithms seems to show better results."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":432},"id":"qyp_jrMCEkgP","executionInfo":{"elapsed":329,"status":"ok","timestamp":1631655893310,"user":{"displayName":"Levy Gabriel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1oZgUqGB_6oi--gsnCQuu9LzMpfCX4SJd3TPucw=s64","userId":"05194170306051508520"},"user_tz":180},"outputId":"c12e3c8a-f8c7-4b83-a502-2275f83cc771"},"source":["model = run(ComplementNB(), X_train, X_test, y_train, y_test)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.93      0.98      0.96      1587\n","           1       0.92      0.77      0.84       476\n","\n","    accuracy                           0.93      2063\n","   macro avg       0.93      0.87      0.90      2063\n","weighted avg       0.93      0.93      0.93      2063\n","\n"]},{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{},"output_type":"display_data"}]},{"cell_type":"markdown","metadata":{"id":"_11dXHquhbCk"},"source":["But in the end the ```BernoulliNB()``` model for data distributed according to multivariate Bernoulli distributions showed even better results with the highest accuracy of $95\\%$."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":432},"id":"CPwqXp7EE645","executionInfo":{"elapsed":287,"status":"ok","timestamp":1631655896802,"user":{"displayName":"Levy Gabriel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1oZgUqGB_6oi--gsnCQuu9LzMpfCX4SJd3TPucw=s64","userId":"05194170306051508520"},"user_tz":180},"outputId":"e9287f99-0ff5-4624-c174-211be47c8c1c"},"source":["model = run(BernoulliNB(), X_train, X_test, y_train, y_test)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.94      1.00      0.97      1587\n","           1       1.00      0.77      0.87       476\n","\n","    accuracy                           0.95      2063\n","   macro avg       0.97      0.89      0.92      2063\n","weighted avg       0.95      0.95      0.95      2063\n","\n"]},{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{},"output_type":"display_data"}]},{"cell_type":"markdown","metadata":{"id":"UL2LuG0vJ1Lv"},"source":["### Hyperparameter tunning"]},{"cell_type":"markdown","metadata":{"id":"le5XbdF1h4KT"},"source":["Not satisfied with previous results the hyperparameter tunning was applied to each of the previous naive Bayes models changing, mainly, its alpha factor and, aditionally, the parameters for vectorization the TF-IDF in feature extraction."]},{"cell_type":"code","metadata":{"id":"widb-BCAMzil","executionInfo":{"status":"ok","timestamp":1631677359732,"user_tz":180,"elapsed":279,"user":{"displayName":"Levy Gabriel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1oZgUqGB_6oi--gsnCQuu9LzMpfCX4SJd3TPucw=s64","userId":"05194170306051508520"}}},"source":["def run(clf, X_train, X_test, y_train, y_test):\n","  steps = [('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', clf)] \n","  pipeline = Pipeline(steps)\n","  parameters = {\n","                'vect__ngram_range': [(1,1), (1,2), (2,2)],\n","                'vect__max_df': (0.5, 0.75, 1.0),\n","                'vect__max_features': (None, 100, 1000, 10000),\n","                'tfidf__use_idf': (True, False),\n","                'clf__alpha': (1e-3, 1e-2, 1e-1, 0.5, 1)\n","  }\n","  model = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=True)\n","  model = model.fit(X_train, y_train)\n","  predictions = model.predict(X_test)\n","  print(model.best_params_)\n","  print(model.best_score_)\n","  print(classification_report(y_test, predictions))\n","  print(confusion_matrix(y_test, predictions))\n","  plot_confusion_matrix(model, X_test, y_test, cmap='gray', values_format='d')  \n","  plt.show()  \n","  return model"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":653},"id":"6fiLqFWaG7fl","executionInfo":{"elapsed":499471,"status":"ok","timestamp":1631656545582,"user":{"displayName":"Levy Gabriel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1oZgUqGB_6oi--gsnCQuu9LzMpfCX4SJd3TPucw=s64","userId":"05194170306051508520"},"user_tz":180},"outputId":"e1d8a3e2-e465-4f7f-e19d-88791b1713b6"},"source":["model = run(MultinomialNB(), train['text'], test['text'], train['target'], test['target'])"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 5 folds for each of 360 candidates, totalling 1800 fits\n"]},{"name":"stderr","output_type":"stream","text":["[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   14.3s\n","[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:   56.3s\n","[Parallel(n_jobs=-1)]: Done 446 tasks      | elapsed:  2.1min\n","[Parallel(n_jobs=-1)]: Done 796 tasks      | elapsed:  3.7min\n","[Parallel(n_jobs=-1)]: Done 1246 tasks      | elapsed:  5.8min\n","[Parallel(n_jobs=-1)]: Done 1796 tasks      | elapsed:  8.3min\n","[Parallel(n_jobs=-1)]: Done 1800 out of 1800 | elapsed:  8.3min finished\n"]},{"name":"stdout","output_type":"stream","text":["{'clf__alpha': 0.001, 'tfidf__use_idf': False, 'vect__max_df': 0.5, 'vect__max_features': 100, 'vect__ngram_range': (1, 1)}\n","0.9921219462951747\n","              precision    recall  f1-score   support\n","\n","           0       0.99      1.00      1.00      1587\n","           1       0.99      0.97      0.98       476\n","\n","    accuracy                           0.99      2063\n","   macro avg       0.99      0.99      0.99      2063\n","weighted avg       0.99      0.99      0.99      2063\n","\n","[[1584    3]\n"," [  12  464]]\n"]},{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{},"output_type":"display_data"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":653},"id":"BXchxbVMIH5t","executionInfo":{"elapsed":501200,"status":"ok","timestamp":1631657046755,"user":{"displayName":"Levy Gabriel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1oZgUqGB_6oi--gsnCQuu9LzMpfCX4SJd3TPucw=s64","userId":"05194170306051508520"},"user_tz":180},"outputId":"26daf7b5-4d3f-4471-fa72-287ed608794f"},"source":["model = run(ComplementNB(), train['text'], test['text'], train['target'], test['target'])"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 5 folds for each of 360 candidates, totalling 1800 fits\n"]},{"name":"stderr","output_type":"stream","text":["[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   12.8s\n","[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:   54.8s\n","[Parallel(n_jobs=-1)]: Done 446 tasks      | elapsed:  2.1min\n","[Parallel(n_jobs=-1)]: Done 796 tasks      | elapsed:  3.7min\n","[Parallel(n_jobs=-1)]: Done 1246 tasks      | elapsed:  5.8min\n","[Parallel(n_jobs=-1)]: Done 1796 tasks      | elapsed:  8.3min\n","[Parallel(n_jobs=-1)]: Done 1800 out of 1800 | elapsed:  8.3min finished\n"]},{"name":"stdout","output_type":"stream","text":["{'clf__alpha': 0.1, 'tfidf__use_idf': False, 'vect__max_df': 0.5, 'vect__max_features': None, 'vect__ngram_range': (1, 2)}\n","0.9710340473175119\n","              precision    recall  f1-score   support\n","\n","           0       0.99      0.97      0.98      1587\n","           1       0.91      0.97      0.94       476\n","\n","    accuracy                           0.97      2063\n","   macro avg       0.95      0.97      0.96      2063\n","weighted avg       0.97      0.97      0.97      2063\n","\n","[[1541   46]\n"," [  15  461]]\n"]},{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{},"output_type":"display_data"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":653},"id":"uK6QQtCzILam","executionInfo":{"status":"ok","timestamp":1631679003529,"user_tz":180,"elapsed":544859,"user":{"displayName":"Levy Gabriel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1oZgUqGB_6oi--gsnCQuu9LzMpfCX4SJd3TPucw=s64","userId":"05194170306051508520"}},"outputId":"283c4c6a-4489-4321-ef11-69dc369052ca"},"source":["model = run(BernoulliNB(), train['text'], test['text'], train['target'], test['target']) "],"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting 5 folds for each of 360 candidates, totalling 1800 fits\n"]},{"output_type":"stream","name":"stderr","text":["[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   14.9s\n","[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:  1.0min\n","[Parallel(n_jobs=-1)]: Done 446 tasks      | elapsed:  2.2min\n","[Parallel(n_jobs=-1)]: Done 796 tasks      | elapsed:  4.0min\n","[Parallel(n_jobs=-1)]: Done 1246 tasks      | elapsed:  6.2min\n","[Parallel(n_jobs=-1)]: Done 1796 tasks      | elapsed:  9.0min\n","[Parallel(n_jobs=-1)]: Done 1800 out of 1800 | elapsed:  9.1min finished\n"]},{"output_type":"stream","name":"stdout","text":["{'clf__alpha': 0.001, 'tfidf__use_idf': True, 'vect__max_df': 0.5, 'vect__max_features': 100, 'vect__ngram_range': (1, 1)}\n","0.9956368041407412\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      1577\n","           1       1.00      0.99      1.00       486\n","\n","    accuracy                           1.00      2063\n","   macro avg       1.00      1.00      1.00      2063\n","weighted avg       1.00      1.00      1.00      2063\n","\n","[[1576    1]\n"," [   3  483]]\n"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"uUdP2olYiUKi"},"source":["After seeing the results, the conclusion is that the grid search improved the accuracy of all models and with the ```BernoulliNB()``` keeping the position of better model with a accuracy as close as $99.56\\%$, with slightly better results than the neural network, trained with less computational resources, less parameters and using a reduced number of features.\n","\n","The latter model was saved to further analysis."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K6HNNXc5lx8b","executionInfo":{"status":"ok","timestamp":1631679126403,"user_tz":180,"elapsed":271,"user":{"displayName":"Levy Gabriel","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh1oZgUqGB_6oi--gsnCQuu9LzMpfCX4SJd3TPucw=s64","userId":"05194170306051508520"}},"outputId":"bdfc3684-9ccf-46ef-9caa-5fdc8dc1418d"},"source":["dump(model, 'bernoullinb.joblib') \n","#load('bernoullinb.joblib')"],"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['bernoullinb.joblib']"]},"metadata":{},"execution_count":31}]}]}